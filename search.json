[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Author",
    "section": "",
    "text": "I’m a graduate student in the School of Economic, Political and Policy Sciences at the University of Texas at Dallas. I plan on completing my M.S. in Economics in December 2024.\n\nMy academic interests include:\n\nMacro/Microeconomics\n\n\nProgramming (R,Python,Quarto)\n\n\nBusiness and Economic Forecasting\n\n\nData Visualization\n\n\n\nCheck out my resume"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nVincent Tellez\n",
    "section": "",
    "text": "Vincent Tellez\n\nThis is my website for EPPS 6356 with Dr. Ho at the University of Texas at Dallas. Use the options in the navigation bar to see what I’ve been working on."
  },
  {
    "objectID": "Assignment 1.html",
    "href": "Assignment 1.html",
    "title": "EPPS 6356: Assignment 1",
    "section": "",
    "text": "Part 1: Anscombe’s Quartet Data Sets\nThis assignment had us look at Anscombe’s Quartet, a collection of four sets of data points that create the same linear regression model even though the distributions vary greatly across all models.\n\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Generative Art\nFrom AI Artists:  “Generative Art is a process of algorithmically generating new ideas, forms, shapes, colors or patterns. First, you create rules that provide boundaries for the creation process. Then a computer follows those tules to produce new works on your behalf.”\nCheck out a couple examples below:\n RAYTRACER TEST 063 by Anders Hoff\n  Gyre 10-7000 by Mark J. Stock —\n\n\nPart 3: Leaf.R\n\n\n\n\n\n\n\n\n\n\n\n\nPart 4: Chart Critique\nThis graph was created by Veronika Samborska for Our World in Data using data from UNESCO Institute for Statistics.\n [Source](https://ourworldindata.org/data-insights/nearly-half-of-teenagers-globally-cannot-read-with-comprehension)\n The author utilizes several techniques to get their message across. The contrasting styles of the title and subtitle draw the viewer’s attention to the top of the image first. Only four colors are used though multiple countries are listed. Most of the countries are not labeld, bringing attention to those at the top and those at the very bottom of the scale. The global average is reported in the middle. Each group of labeled observations has arrows coming from what are likely the author’s main message. Highlighting the top and lower groups in different colors helps the viewer compare the drastic difference in ratings. Everything on this graph has meaning and the author uses the space wisely."
  },
  {
    "objectID": "Assignments.html",
    "href": "Assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This is where all of the Assignments for Data Visualization will be posted."
  },
  {
    "objectID": "Assignments.html#assignments",
    "href": "Assignments.html#assignments",
    "title": "Assignments",
    "section": "Assignments",
    "text": "Assignments"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This is where all of the Assignments for Data Visualization will be posted."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test",
    "section": "",
    "text": "Here is a test file. Let’s see how it looks."
  },
  {
    "objectID": "assignmain.html",
    "href": "assignmain.html",
    "title": "EPPS 6356",
    "section": "",
    "text": "This page is dedicated to the work I’ve completed for Dr. Karl Ho’s course in Data Visualization at the University of Texas at Dallas. Below, you can click the assignment titles to take you wherever you need to go.\nIf something doesn’t look right or a link isn’t you taking where it’s supposed to go, please shoot me an email:  vdt200000@utdallas.edu"
  },
  {
    "objectID": "assignmain.html#assignments",
    "href": "assignmain.html#assignments",
    "title": "EPPS 6356",
    "section": "Assignments",
    "text": "Assignments\n\nAssignment 1\nHere, we take a look at Anscombe’s Quartet, as well as a lovely leaf graphic created in R. Beneath the plots, you’ll find my critique on a chart I found out online.\n\n\nAssignment 2*\nAn introduction to creating visuals with R Graphics, this assignment takes a look at one of Paul Murrell’s RGraphics basic R programs. We conclude this assignment by recreating the same charts using data from the Happy Planet Index.\n\n\nAssignment 3\nWe take the previous assignments one step further. After analyzing one of the plots from Assignment 2, we revist Anscombe’s quartet and give it a facelift with RGraphics, and later ‘ggplot2’. We wrap up this section with the team’s Pre-Hackathon submission.\n\n\nAssignment 4*\nHackathon Officially begins! Tasked with recreating several plots in R, the team jumps back into ‘ggplot2’. Click on title to see what the team came up with.\n\n\nAssignment 5*\nThis assignment takes plotting in R to another level. The first group of graphs was produced using only R Graphics. The latter collection of charts was created using ‘ggplot2’.\n\n\nAssignment 6*\nMore practice with Shiny applications. There are three applications featured in this section. The first app and dataset came from Dr. Ho, the second uses some datasets that come built-in with R, the last is uses our final project data.\n\n\nAssignment 7*\nReturn of Hackathon! This time around we are builing a shiny app that uses the ‘mtcars’ data from R.\n\n\nAssigment 8\nWe were tasked with building a Plotly dashboard using some of our final data. I chose to display three bar charts comparing four different metrics for the Tech, Industrial, Healthcare and Financial Sectors. The graphs display data for three different time periods before and after the 2020 U.S. presidential election. I used one of the dashboard templtates provided by Dr. Ho as a starting point.\n\n\n*Disclaimer: ChatGPT assisted with writing the code for these assignments."
  },
  {
    "objectID": "assignmain.html#reviews",
    "href": "assignmain.html#reviews",
    "title": "EPPS 6356",
    "section": "Reviews",
    "text": "Reviews"
  },
  {
    "objectID": "assignment7.html",
    "href": "assignment7.html",
    "title": "EPPS 6356: Assignment 7",
    "section": "",
    "text": "Guidelines:\n\nMust use R Graphics or ggplot2\nMust be completed within 48 hours\nThe app must generate a Scatter Plot (Two Variables), Bubble Chart, and one additional chart (teams choose)."
  },
  {
    "objectID": "assignment8.html",
    "href": "assignment8.html",
    "title": "U.S. Stock Sector Analysis",
    "section": "",
    "text": "Comparing Stock Sector Metrics by Date Range\n\n\nIntroduction\n\n      The following horizontal bar graphs compare sector performance with four analytical measures for the 2020 U.S. presidential election. The first is drawdown, which describes a fall in share or portfolio price as a percentage of the peak price for the specified time. The second is volatility, or the standard deviation of returns for the period multiplied by the square root of the number of trading days, estimated at 252 days each year. Multiplying the volatility by 100 allows the bar graphs to report them as percentages. Sectors with lower volatility experience fewer price fluctuations, and vice versa.\n\n      The last two metrics, alpha, and beta, compare sector performance to a benchmark index for the market. This paper uses the S&P 500 index. The alpha metric reports how much better or worse the sector did compared to the S&P 500. For example, if the alpha is 3%, this sector earned 3% more than the S&P 500 did for the period, the opposite is true for negative alpha values. Beta, on the other hand, compares sector volatility to that of the benchmark index. With the index fixed at 1, betas greater than 1 are considered more volatile than the market, and those below 1 are less volatile than the benchmark for that period.\n\nTo implement the calculation of these variables in R, several packages are required:\n\n\nR package ‘readxl’ imports the dataset\n\n\nR packages ‘dyplr’ and ‘tidyr’ aid in data manipulation for panel data\n\n\n‘quantmod’ is a package that digests the stock data and calculates useful metrics like daily and average returns, which are needed to calculate the above metrics\n\n\n‘ggplot2’ allows the final visualizations to be organized and customized for readability\n\n\n\n60 Days before and After the 2020 Election\n\n\nWarning: package 'openxlsx' was built under R version 4.3.3\n\n\n\n\n\n\n\n\n\n\n\nWe can see there are significant changes between the two time periods. The Tech sector has greatly improved performance, however, the Healthcare sector does not exhibit the same improvements. We also see that volatility in the financial sector continued to increase where other sectors had decreases in their volatility.\n\n\n30 Days before and after the 2020 Election\n\n\n\n\n\n\n\n\n\n\n\nComparing these time frames to the previous ones, we see an increase in volatility for every sector except for healthcare. We also see the 30 days after measures decrease as it transitions into the 60 day mark. Overall, the sectors are performing decently. There are likely some improvements to be made.\n\n\n15 Days before and after the 2020 Election\n\n\n\n\n\n\n\n\n\n\n15 days after the election we see the financial volatility peak. This value almost doubles from the volatility 15 days before the election. We had expected to see strong performance in the Healthcare and Tech sectors. The Tech sector improved, but the healthcare sector did not.\n\n\nConclusion\n\n      Per Hypothesis I, some sectors do experience increased volatility as proximity to the election increases, primarily the financial and industrial sectors, but this is not seen across the other sectors. Since Biden was the democratic nominee, the tech and healthcare sectors are expected to experience greater performance. The returns on the tech sector prices are greater than the benchmark’s returns for the periods leading up to the election, however, afterwards the returns fall below the market. This is not true for the healthcare sector, whose returns are less than the benchmark for all periods before and after the election. Beta values for the tech sector indicate a decline in volatility compared to the market as the time before the election decreased, eventually resulting in the volatility of the sector falling below the benchmark’s volatility. Along with the reduced drawdown before and after the election, these metrics indicate strong performance in the tech sector. The betas for the healthcare sector show slight increases in volatility before the election and clear increases in volatility after the election. Healthcare drawdown decreases closer to the election but then increases significantly after the election. This sector did not experience the same positive performance as the tech sector.\n\n      Using similar analytical interpretations for the other two sectors, the financial sector had large swings in volatility and drawdown after the election. The industrial sector’s volatility peaked on election day but proceeded to decline steadily afterward. Tech had the greatest improvement in performance compared to the other sectors for this election."
  },
  {
    "objectID": "assignment_4.html",
    "href": "assignment_4.html",
    "title": "EPPS 6356: Assignment 4",
    "section": "",
    "text": "Our team was tasked with creating four specific plots using only R (R Graphics, ggplot2, etc.):\n\n\nVariable Width Column Chart\n\n\nTable with Embedded Charts\n\n\nBar Chart\n\n\nColumn Chart\n\n\nI’ve included the R code for each plot in the code-folds.\n\nPlot 1: Variable Width Column Chart\n\n\nCode\n#|echo: false\n# This dataset generation code was provided with assistance from ChatGPT\n# Set seed for reproducibility\nset.seed(123)\n\n# Generate a dataset\ndf &lt;- data.frame(\n  ID = 1:100,  # IDs from 1 to 100\n  Category = sample(c(\"A\", \"B\", \"C\"), 100, replace = TRUE),  # Randomly assign categories\n  Value = round(runif(100, min = 10, max = 100), 2),  # Random values between 10 and 100\n  Date = sample(seq(as.Date('2020-01-01'), as.Date('2021-01-01'), by=\"day\"), 100, replace = TRUE)  # Random dates\n)\n\n# View the first few rows of the dataset\n# head(df)\n\nlibrary(ggplot2)\n\ndf_summary &lt;- aggregate(Value ~ Category, df, mean)\n\nggplot(df_summary, aes(x = Category, y = Value)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\", color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Average Value by Category\", x = \"Category\", Y = \"Value\") +\n  geom_text(aes(label = round(Value, 2)), vjust = -0.5)\n\n\n\n\n\n\n\n\n\n\n\nPlot 2: Table with Embedded Charts\n\n\nCode\n#|echo: false\n# Chatgpt was used to assist with the coding\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(gridExtra)\n  \n# Reshape the Anscombe data for ggplot2 (long format)\nanscombe_long &lt;- data.frame(\n  x = c(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4),\n  y = c(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4),\n  group = rep(c(\"Set 1\", \"Set 2\", \"Set 3\", \"Set 4\"), each = nrow(anscombe))\n)\n  \n# Create a new plotting function for bar charts\ngg_anscombe_bar &lt;- function(data, group_label) {\n  ggplot(data, aes(x = as.factor(x), y = y)) +  # Convert x to factor for bar chart\n    geom_bar(stat = \"identity\", aes(fill = group_label), color = \"black\") +  # Create bars\n    labs(title = paste(\"Bar Chart: \", group_label), x = \"x\", y = \"Sum of y\") +\n    theme_minimal(base_family = \"serif\") +  # Set font to serif\n    theme(plot.title = element_text(hjust = 0.5, size = 14))  # Center the title\n}\n  \n# Bar Plot 1\nbp1 &lt;- gg_anscombe_bar(anscombe_long[anscombe_long$group == \"Set 1\", ], \"Set 1\") +\n  scale_fill_manual(values = \"red\")\n  \n# Bar Plot 2\nbp2 &lt;- gg_anscombe_bar(anscombe_long[anscombe_long$group == \"Set 2\", ], \"Set 2\") +\n  scale_fill_manual(values = \"darkgreen\")\n  \n# Bar Plot 3\nbp3 &lt;- gg_anscombe_bar(anscombe_long[anscombe_long$group == \"Set 3\", ], \"Set 3\") +\n  scale_fill_manual(values = \"orange\")\n  \n# Bar Plot 4\nbp4 &lt;- gg_anscombe_bar(anscombe_long[anscombe_long$group == \"Set 4\", ], \"Set 4\") +\n  scale_fill_manual(values = \"blue\")\n  \n# Arrange the four bar charts into a grid\ngrid.arrange(bp1, bp2, bp3, bp4, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\nPlot 3: Bar Chart\n\n\nCode\n#|echo: false\nlibrary(ggplot2)\n\n# Citation: This code was generated using ChatGPT.\n# Summarize the dataset\n# We'll use 'mtcars' dataset and create a bar chart of car models vs their horsepower (hp)\ndata &lt;- mtcars\ndata$car_model &lt;- rownames(data)\n\n# Create a horizontal bar chart\nggplot(data, aes(x = hp, y = reorder(car_model, hp))) +\n  geom_bar(stat = \"identity\", fill = \"lightcoral\") +\n  labs(title = \"Horsepower of Car Models in mtcars Dataset\",\n       x = \"Horsepower (hp)\", y = \"Car Models\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nPlot 4: Column Chart\n\n\nCode\n#|echo: false\n# Citation: This code was generated using ChatGPT.\ndata &lt;- mtcars\ndata$transmission &lt;- ifelse(data$am == 0, 'Automatic', 'Manual')\n\n# Summarize data: Average mpg by number of cylinders and transmission type\ndata_summary &lt;- aggregate(mpg ~ cyl + transmission, data, mean)\n\n# Create a grouped column chart\nggplot(data_summary, aes(x = factor(cyl), y = mpg, fill = transmission)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  labs(title = \"Average MPG by Cylinder and Transmission Type (mtcars Dataset)\", \n       x = \"Number of Cylinders\", y = \"Miles per Gallon (MPG)\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Automatic\" = \"lightblue\", \"Manual\" = \"lightcoral\"))"
  },
  {
    "objectID": "assignmain.html#final-project",
    "href": "assignmain.html#final-project",
    "title": "EPPS 6356",
    "section": "Final Project",
    "text": "Final Project\nIn this assignment, we take a look at the impact of proximity to U.S. presidential elections on several sectors in the U.S. Economy. The application uses Heatmaps, Time Series, Bar Plots, and and Efficient Frontier to give the User a better idea of what happens to the following sectors:\n\n\nTech\n\n\nFinancial\n\n\nHealthcare\n\n\nIndustrial\n\n\nAerospace & Defense (Efficient Frontier only)\n\n\nFor the full write up and methodology behind this project click here. The R code for our app and data used for this project can be found here."
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "EPPS 6356: Assignment 2",
    "section": "",
    "text": "Part 1: Paul Murrell’s R Graphics B R program\nThe adjustments made to the code are written in the comments by each request.\n\n\nCode\n### Paul Murrell's R examples (selected)\n# Code provided by Dr. Ho\n## Start plotting from basics \n# Note the order\nplot(pressure, pch=18)  # Can you change pch? Yes &gt;&gt; changed to 18\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\n\n\nCode\n#  Examples of standard high-level plots \n#  In each case, extra output is also added using low-level \n#  plotting functions.\n# \n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Scatterplot\n# Note the incremental additions\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=1) # Try different cex value?  Changed from 2 -&gt; 1\npoints(x, y2, pch=21, bg=\"antiquewhite\", cex=2)  # Different background color\n# Changed to antiquewhite\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for?\n  # the first number is for the x-axis\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY &lt;- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6)))\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Plotting with the Happy Planet Index\nThe following plots use 2020 data from the Happy Planet Index. 28 different countries are included in this dataset. The variables included are: Country/Continent, Population, Life Expectancy, Ladder of Life, Carbon Footrpint, HPI, CO2 Threshold for the Year, and GDP per Capita. I’ve included definitions for the functions in the code comments.\nClick here for more information on the Happy Planet Index and a link to download the dataset.\n\n\nCode\n# Disclaimer: ChatGPT assisted with writing this code\nlibrary(tidyr) # for dropping NAs\n\ndata &lt;- read.csv('hpi_global_2020.csv')\n\n# Set up the table with 3 rows and 2 columns\n  # Just like in Murrell's example\npar(mfrow = c(3, 2))\n\n# 1. Line graph of GDP per capita vs Life Expectancy\nplot(data$`GDP.per.capita....`, data$`Life.Expectancy..years.`,\n     type = \"n\", main = \"Life Expectancy vs GDP\",\n     xlab = \"GDP per Capita ($)\", ylab = \"Life Expectancy (years)\")\n  # This sets up our axis and first plotting area\nlines(data$`GDP.per.capita....`, data$`Life.Expectancy..years.`, col = \"purple4\")\n  # This function draws the lines that connect out points\npoints(data$`GDP.per.capita....`, data$`Life.Expectancy..years.`, col = \"darkorange1\")\n# axis(1, at=seq(1, 8, 1))\n# 'axis()' let's you draw custom axes\n\n# 2. Histogram of Life Expectancy\nhist(data$`Life.Expectancy..years.`, main = \"Histogram of Life Expectancy\",\n     xlab = \"Life Expectancy (years)\", col = \"lightgreen\", breaks = 10)\n  # This creates the histogram and its labels\n\n# 3. Bar plot - Average Wellbeing per Continent\navg_wellbeing &lt;- tapply(data$`Ladder.of.life..Wellbeing...0.10.`, data$Continent, mean)\nbarplot(avg_wellbeing, main = \"Average Wellbeing by Continent\",\n        xlab = \"Continent\", ylab = \"Average Wellbeing\", col = \"orange\")\n  # This plots the bar plot and labels it\n\n# 4. Box plot: Carbon Footprint by Continent\nboxplot(data$`Carbon.Footprint..tCO2e.` ~ data$Continent, main = \"Carbon Footprint by Continent\",\n        xlab = \"Continent\", ylab = \"Carbon Footprint (tCO2e)\", col = \"lightblue\")\n  # This function creates the box plot in one go\nlegend(4.5, 35,legend = c(\"1-L.Am. 2-N.Am. 3-W. Eu. 4-Mid. E.\", \"5-Afr. 6-S. Asia 7-E.Eu./C. Asia 8-E. Asia\"))\n  # This function adds a legend to a plot at the coordinates you set\n\n# 5. Perspective plot of GDP and Life Expectancy\n# Drop NAs\ndata1 &lt;- data %&gt;% drop_na(GDP.per.capita....)\n\nx &lt;- seq(min(data1$`GDP.per.capita....`),max(data1$`GDP.per.capita....`) , length.out = 10)\ny &lt;- seq(min(data1$`Life.Expectancy..years.`), max(data1$`Life.Expectancy..years.`), length.out = 10)\nz &lt;- outer(x, y, function(x, y) x * y / 10000) # Example relationship\npersp(x, y, z, theta = 30, phi = 20, main = \"Perspective Plot\",\n      xlab = \"GDP per Capita\", ylab = \"Life Expectancy\", zlab = \"Scaled Value\", col = \"rosybrown1\")\n\n# 6. Pie chart: Population distribution for the top 5 countries by population\ntop_countries &lt;- data[order(-data$`Population..thousands.`), ][1:5, ]\npie(top_countries$`Population..thousands.`, labels = top_countries$Country,\n    main = \"Top 5 Countries by Population\", col = rainbow(6))\n\n\n &lt;img src=“/images/assign2_plots.png”, alt=“A series of plots made using HPI data”, width = “1000”&gt;"
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "EPPS 6356: Assignment 3",
    "section": "",
    "text": "Part 1: Disecting the Pie Chart from ‘murrell01.R’\n\n\nCode\n#|echo: False\n#|\n# Pie chart\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\n# this assigns the proportions of each flavor to a list called        'pie.sales'\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\n# The above code assigns flavors (names) to each of the proportions in 'pie.sales'. They are ordered, so Blueberry is 0.12, Cherry is 0.3, etc.\n# The 'pie()' actually creates the pie. It uses the 'pie.sales' as the data. The 'col' argument assigns each flavor a different shade of gray. The 6 shades range from 30% opacity to 100% opacity (equally spaced apart).\npie(pie.sales, col = gray(seq(0.3,1.0,length=6))) \n\n\n\n\n\n\n\n\n\n While the chart has no title, we can infer from the code that it displays six pie flavors as proportions of total pie sales. Specifics behind the code can be found in the comments.\n\n\n\nPart 2: Rerun ‘anscombe01.R’\n\n\nCode\n#|echo: False\n## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\nView(anscombe) # View the data\nsummary(anscombe)\n\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\nCode\n## Simple version\nplot(anscombe$x1,anscombe$y1)\n\n\n\n\n\n\n\n\n\nCode\nsummary(anscombe)\n\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\nCode\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\n\nCode\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\n\nCode\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\n\nCode\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n\nCode\n#plot(anscombe$x1,anscombe$y1)\n#abline(coefficients(lm1))\n#plot(anscombe$x2,anscombe$y2)\n#abline(coefficients(lm2))\n#plot(anscombe$x3,anscombe$y3)\n#abline(coefficients(lm3))\n#plot(anscombe$x4,anscombe$y4)\n#abline(coefficients(lm4))\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nsapply(mods, coef)  # Note the use of this function\n\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\nCode\nlapply(mods, function(fm) coef(summary(fm)))\n\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n\nCode\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\n\n\nCode\npar(op)\n\n\n As we saw in Assignment 1, these regression models all conclude with similar estimated coefficients. However, they all look very different graphically. The actual distributions of points, while very different, were able to pull the slope in the same direction.  The colors chosen for the plot clearly differentiate the points from the regression lines. Blue and orange are on opposite ends of the color wheel, so this is not surprising. I suspect that similar outcomes can be reached by using more colors that are opposites on the color wheel, the contrast makes everyhting pop. You could also consider changing the font of labels to make them stand out from the relatively plain x-tick markers. Adding a grid to the background of the plot could make it easier to get an estimate for the true coordainates for each point. Lastly, the title could be changed to an eye catching font.\n\n\n\nPart 3: Finetune using R Graphics\n\n\nUse a Serif Font\n\n\nUse non-default colors\n\n\nUse a different plotting character\n\n\n\n\nCode\n## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\n#View(anscombe) # View the data\n#summary(anscombe)\n\n## Simple version\n#plot(anscombe$x1,anscombe$y1)\n#summary(anscombe)\n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\n#summary(lm1)\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\n#summary(lm2)\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\n#summary(lm3)\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\n#summary(lm4)\n#plot(anscombe$x1,anscombe$y1)\n#abline(coefficients(lm1))\n#plot(anscombe$x2,anscombe$y2)\n#abline(coefficients(lm2))\n#plot(anscombe$x3,anscombe$y3)\n#abline(coefficients(lm3))\n#plot(anscombe$x4,anscombe$y4)\n#abline(coefficients(lm4))\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nsapply(mods, coef)  # Note the use of this function\nlapply(mods, function(fm) coef(summary(fm)))\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"blueviolet\", pch = 23, bg = \"plum1\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"darkolivegreen3\")\n}\nmtext(substitute(paste(bold(\"Anscombe's 4 Regression data sets\"))), outer = TRUE, cex = 1.5, side = 3, adj = 0.1, family = \"serif\")\n\n\n\n\n\n\n\n\n\nCode\npar(op)\n\n\n\n\n\nPart 4: Try it with ‘ggplot2’\n\n\nCode\n# Disclaimer: This code was partially generated by ChatGPT\n# Load necessary libraries\nlibrary(gridExtra)\nlibrary(ggplot2)\n\ndata(anscombe)\n# Reshape the Anscombe data for ggplot2 (long format)\nanscombe_long &lt;- data.frame(\n  x = c(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4),\n  y = c(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4),\n  group = rep(c(\"Set 1\", \"Set 2\", \"Set 3\", \"Set 4\"), each = nrow(anscombe))\n)\n\n# Define a plot function to customize each plot\ngg_anscombe &lt;- function(data, group_label) {\n  ggplot(data, aes(x = x, y = y)) +\n    geom_point(aes(color = group_label), size = 3, shape = 16) +\n    geom_smooth(method = \"lm\", se = FALSE, aes(color = group_label), size = 1) +\n    labs(title = paste(\"Regression: \", group_label), x = \"x\", y = \"y\") +\n    theme_minimal(base_family = \"serif\") +  # Set font to serif\n    theme(plot.title = element_text(hjust = 0.5, size = 14))  # Center the title\n}\n\n# Plot 1\np1 &lt;- gg_anscombe(anscombe_long[anscombe_long$group == \"Set 1\", ], \"Set 1\") +\n  geom_point(color = \"red\", shape = 16) +  # Red points, filled circles\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\", linetype = 1)  # Blue solid line\n\n# Plot 2\np2 &lt;- gg_anscombe(anscombe_long[anscombe_long$group == \"Set 2\", ], \"Set 2\") +\n  geom_point(color = \"darkgreen\", shape = 17) +  # Green points, triangles\n  geom_smooth(method = \"lm\", se = FALSE, color = \"purple\", linetype = 2)  # Purple dashed line\n\n# Plot 3\np3 &lt;- gg_anscombe(anscombe_long[anscombe_long$group == \"Set 3\", ], \"Set 3\") +\n  geom_point(color = \"orange\", shape = 15) +  # Orange points, squares\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = 3)  # Black dotted line\n\n# Plot 4\np4 &lt;- gg_anscombe(anscombe_long[anscombe_long$group == \"Set 4\", ], \"Set 4\") +\n  geom_point(color = \"blue\", shape = 1) +  # Blue open circles\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\", linetype = 4)  # Red dot-dash line\n\n# Arrange the four plots into a grid\ngrid.arrange(p1, p2, p3, p4, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nPart 5: Pre-Hackathon\nMy team was unable to reproduce Dr. Ho’s graph perfectly. This is as close as we got."
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "EPPS 6356: Assignment 5",
    "section": "",
    "text": "Part 1: More Practice with R Graphics\n\n\nCode\n# Disclaimer: ChatGPT assisted with writing this code\n# multi-chart again\npar(mfrow = c(3, 2), family = \"sans\", bg = \"#f2eef2\") # 3 rows, 2 columns layout\n\n# Histogram - Miles Per Gallon (mpg) in mtcars\nhist(mtcars$mpg, \n     main = \"Histogram of Miles Per Gallon (mpg)\", \n     xlab = \"Miles Per Gallon\", \n     col = \"blueviolet\", \n     border = \"purple4\")\n\n# Horizontal Bar Chart - Frequency of Cylinders in mtcars\ncyl_table &lt;- table(mtcars$cyl)\nbarplot(cyl_table, \n        horiz = TRUE, \n        main = \"Horizontal Bar Chart of Cylinders\", \n        xlab = \"Frequency\", \n        col = c(\"purple1\", \"mediumpurple1\", \"purple4\"))  \n\n# Vertical Bar Chart - Average Sepal Width by Species in iris\niris_means &lt;- tapply(iris$Sepal.Width, iris$Species, mean)\nbarplot(iris_means, \n        main = \"Vertical Bar Chart of Sepal Width\", \n        ylab = \"Average Sepal Width\", \n        col = c(\"mediumorchid\", \"lavender\", \"plum\"))\n\n# Pie Chart - Proportion of Cylinders in mtcars\npie(cyl_table, \n    main = \"Pie Chart of Cylinders\", \n    col = c(\"palevioletred\", \"thistle3\", \"thistle1\"))\n\n# Box Plot - Monthly Air Passengers\nboxplot(AirPassengers, \n        main = \"Boxplot of Monthly Air Passengers\", \n        ylab = \"Passengers\", \n        col = \"#ca9bf7\")\n\n# Scatter Plot - Sepal Length vs. Sepal Width in iris\nplot(iris$Sepal.Length, iris$Sepal.Width, \n     main = \"Scatter Plot of Sepal Dimensions\", \n     xlab = \"Sepal Length\", \n     ylab = \"Sepal Width\", \n     col = \"magenta4\", bg = \"magenta1\", \n     pch = 23)\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Redo with ‘ggplot2’\n\n\nCode\n# Load the ggplot2 package\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Histogram - Miles Per Gallon (mpg) in mtcars\ng1 &lt;- ggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(binwidth = 2, fill = \"#8870b9\", color = \"#3c2268\") +\n  labs(title = substitute(paste(bold(\"Histogram of Miles Per Gallon (mpg)\"))), x = \"Miles Per Gallon\", y = \"Count\") +\n  theme(plot.title = element_text(family = 'serif', face = \"bold.italic\", size = 12),\n        axis.title.x = element_text(family = 'sans', face = 'italic', size = 10),\n        axis.title.y= element_text(family = 'sans', face = 'italic', size = 10),\n        axis.text.x = element_text(family = 'sans', face = 'plain', size = 8),\n        axis.text.y = element_text(family = 'sans', face = 'plain', size = 8),\n    panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\", linewidth = 0.5, \n                                            linetype = \"solid\"),\n    panel.grid.major = element_line(size = 0.25, linetype = 'solid',\n                                    colour = \"thistle3\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                    colour = \"thistle3\"))\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nCode\n# Horizontal Bar Chart - Frequency of Cylinders in mtcars\ncyl_table &lt;- as.data.frame(table(mtcars$cyl))\ng2 &lt;- ggplot(cyl_table, aes(x = Freq, y = Var1)) +\n  geom_bar(stat = \"identity\", fill = c(\"#631c99\", \"#987ab4\", \"#290053\")) +\n  labs(title = substitute(paste(bold(\"Horizontal Bar Chart of Cylinders\"))), x = \"Frequency\", y = \"Cylinders\") +\n  coord_flip() +\n  theme(plot.title = element_text(family = 'serif', face = \"bold.italic\", size = 12),\n        axis.title.x = element_text(family = 'sans', face = 'italic', size = 10),\n        axis.title.y= element_text(family = 'sans', face = 'italic', size = 10),\n        axis.text.x = element_text(family = 'sans', face = 'plain', size = 8),\n        axis.text.y = element_text(family = 'sans', face = 'plain', size = 8),\n        panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\", linewidth = 0.5, \n                                        linetype = \"solid\"),panel.grid.major = element_line(size = 0.25, linetype = 'solid',\n                                    colour = \"thistle3\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                    colour = \"thistle3\"))\n\n# Vertical Bar Chart - Average Sepal Width by Species in iris\niris_means &lt;- aggregate(Sepal.Width ~ Species, data = iris, mean)\ng3&lt;- ggplot(iris_means, aes(x = Species, y = Sepal.Width, fill = Species)) +\n  geom_bar(stat = \"identity\", fill = c(\"darkmagenta\", \"#758eb7\", \"#6f5f90\")) +\n  labs(title = substitute(paste(bold(\"Vertical Bar Chart of Sepal Width\"))), y = \"Average Sepal Width\", x = \"Species\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(family = 'serif', face = \"bold.italic\", size = 12),\n        axis.title.x = element_text(family = 'sans', face = 'italic', size = 10),\n        axis.title.y= element_text(family = 'sans', face = 'italic', size = 10),\n        axis.text.x = element_text(family = 'sans', face = 'plain', size = 8),\n        axis.text.y = element_text(family = 'sans', face = 'plain', size = 8),\n        panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\", linewidth = 0.5, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"), \n        panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"))\n\n# Pie Chart - Proportion of Cylinders in mtcars\ng4 &lt;- ggplot(cyl_table, aes(x = \"\", y = Freq, fill = Var1)) +\n  geom_col(color = \"#3c2268\") +\n  labs(title = \"Pie Chart of Cylinders\", x = NULL, y = NULL) +\n  geom_text(aes(label = Freq),\n            position = position_stack(vjust = 0.5)) +\n  coord_polar(theta = \"y\") +\n  scale_fill_brewer() +\n  theme_void() +\n  theme(plot.title = element_text(family = 'serif', face = \"bold\", size = 12),\n        panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\"))\n\n\n# Box Plot - Monthly Air Passengers\nair_data &lt;- data.frame(Passengers = as.numeric(AirPassengers))\ng5 &lt;- ggplot(air_data, aes(y = Passengers)) +\n  geom_boxplot(fill = \"slateblue\", color = \"#3c2268\") +\n  labs(title = substitute(paste(bold(\"Boxplot of Monthly Air Passengers\"))), y = \"Passengers\") +\n  theme(legend.title = element_blank(), plot.title = element_text(family = 'serif', face = \"bold.italic\", size = 12),\n        axis.title.x = element_text(family = 'sans', face = 'italic', size = 10),\n        axis.title.y= element_text(family = 'sans', face = 'italic', size = 10),\n        axis.text.x = element_text(family = 'sans', face = 'plain', size = 8),\n        axis.text.y = element_text(family = 'sans', face = 'plain', size = 8),\n        panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\", linewidth = 0.5, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"), \n        panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"))\n\n# Scatter Plot - Sepal Length vs. Sepal Width in iris\ng6 &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(color = \"purple4\", shape = 23, col = \"#411b46\", bg = \"#966fd6\") +\n  labs(title = substitute(paste(bold(\"Scatter Plot of Sepal Dimensions\"))), x = \"Sepal Length\", y = \"Sepal Width\") +\n  theme(legend.title = element_blank(), plot.title = element_text(family = 'serif', face = \"bold.italic\", size = 12),\n        axis.title.x = element_text(family = 'sans', face = 'italic', size = 10),\n        axis.title.y= element_text(family = 'sans', face = 'italic', size = 10),\n        axis.text.x = element_text(family = 'sans', face = 'plain', size = 8),\n        axis.text.y = element_text(family = 'sans', face = 'plain', size = 8),\n        panel.background = element_rect(fill = \"#f5f3f6\", color = \"#3c2268\", linewidth = 0.5, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"), \n        panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                        colour = \"thistle3\"))\n\n\nWarning: Duplicated aesthetics after name standardisation: colour\n\n\nCode\n# Combine them\ngrid.arrange(g1, g2, g3, g4, g5, g6, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Image Formats\nDownload Plot Files\nThe above file has each of the following file types:\n\n\nPDFs: These are usually smaller files so they can be shared and stored easier. They can be used for text, images, hyperlinks, and more.\n\n\nJPEG: Another file type that can be easily sized down. This format is common for web images.\n\n\nSVG: These file types are excellent for web images. No matter what size the image is, it will maintain clearness. It will not become pixelated even if blown up to a large size.\n\n\nTIFFs: Professional level photography files. These are high-quality and highly detailed.\n\n\nBMG: These are text or message files."
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "EPPS 6356: Assignment 6",
    "section": "",
    "text": "Part 1: Change Font on Dr. Ho’s Shiny App\nFor reference, the original font was ‘Palatino’. Now it is bold ‘Georgia’ font.\n\n\n\n\n\nPart 2: Build a Shiny App with R Datasets\nUse the following datasets:\n\n\n‘mtcars’\n\n\n‘USArrests’\n\n\n‘uspop’\n\n\n  \n\n\n\nPart 3: Build a Shiny App Using Own Data\nThis application is an earlier version of what became our final project application. It uses the same dataset as the final project."
  }
]